# 关系抽取调研——学术界

## 目录

  * [1. 任务](#1-任务)
     * [1.1. 背景](#11-背景)
     * [1.2. 任务定义](#12-任务定义)
     * [1.3. 数据集](#13-数据集)
     * [1.4. 评测标准](#14-评测标准)
     
  * [2. 方法总结](#2-方法总结)
     * [2.1. 基于模板的方法(hand-written patterns)](#21-基于模板的方法)
        * [2.1.1. 基于触发词/字符串](#221-基于触发词/字符串)
        * [2.1.2. 基于依存句法](#222-基于依存句法)
     * [2.2. 监督学习(supervised machine learning)](#22-基于信息抽取information-extraction的方法)
        * [2.1.1. 机器学习](#221-机器学习)
        * [2.1.2. 深度学习（Pipeline vs Joint Model）](#222-深度学习（Pipeline vs Joint Model）)
     * [2.3. 半监督/无监督学习(semi-supervised and unsupervised)](#23-半监督/无监督学习(semi-supervised and unsupervised))
        * [2.3.1. 远程监督(ML)](#221-远程监督(ML))
        * [2.3.2. Bootstrapping or diplait（Pipeline vs Joint Model）](#222-Bootstrapping or diplait（Pipeline vs Joint Model）)
  * [3. 抽取工具应用](#3-抽取工具应用)
     * [3.1. TextRunner](#31-TextRunner)
     * [3.2. OLLIE：开放三元组知识抽取](#32-OLLIE：开放三元组知识抽取)
  * [4.相关链接](#4-相关链接)
  * [5.参考资源](#4-参考资源)

## 1. 任务

### 1.1. 背景



### 1.2. 任务定义
自动识别句子中实体之间具有的某种语义关系。根据参与实体的多少可以分为二元关系抽取（两个实体）和多元关系抽取（三个及以上实体）。

通过关注两个实体间的语义关系，可以得到（arg1, relation, arg2）三元组，其中arg1和arg2表示两个实体，relation表示实体间的语义关系。

根据处理数据源的不同，关系抽取可以分为以下三种：

- 面向结构化文本的关系抽取：包括表格文档、XML文档、数据库数据等
- 面向非结构化文本的关系抽取：纯文本
- 面向半结构化文本的关系抽取：介于结构化和非结构化之间

根据抽取文本的范围不同，关系抽取可以分为以下两种：

- 句子级关系抽取：从一个句子中判别两个实体间是何种语义关系
- 语料（篇章）级关系抽取：不限定两个目标实体所出现的上下文

根据所抽取领域的划分，关系抽取又可以分为以下两种：

- 限定域关系抽取：在一个或者多个限定的领域内对实体间的语义关系进行抽取，限定关系的类别，可看成是一个文本分类任务
- 开放域关系抽取：不限定关系的类别

限定域关系抽取方法：

- 基于模板的关系抽取方法：通过人工编辑或者学习得到的模板对文本中的实体关系进行抽取和判别，受限于模板的质量和覆盖度，可扩张性不强
- 基于机器学习的关系抽取方法：将关系抽取看成是一个分类问题





### 1.3. 数据集
- **MUC关系抽取任务数据集**

  MUC-7的五大评测任务分别是命名实体识别、共指消解、模板元素填充、模板关系确定和场景模板填充。数据语料主要来自新闻语料，限定领域为飞机失事报道和航天器发射事件报道。

- **ACE关系抽取任务数据集**

  MUC会议停开后，ACE将关系抽取任务作为一个子任务从2002至2007年共持续六年。关系抽取任务也被定义的更加规范和系统。其中，获得认可的一届关系抽取任务主要是ACE-2004，其数据来源于语言数据联盟（LDC），分成广播新闻和新闻专线两部分，总共包括451和文档和5702个关系实例。ACE20014提供了丰富的标注信息，从而为信息抽取中的实体识别、指代消解和关系抽取等子任务提供基准的训练和测试语料库。

- **TAC-KBP数据集**
  TAC会议下的KBP评测下的ESF任务，可以视作是传统的关系抽取任务。该任务主要是抽取关于PER的25种属性和ORG的16种属性。主要是使用维基百科快照作为现有的知识库，从现有的新闻或者网络文本中获取关于实体的现有信息和更新信息，以构建知识库。

- **SemEval2010_task8**  

  一共9种关系类别数，含有6674实例数量

- **FewRel**

   一共100种关系类别数，含有70000实例数量

- **NYT10** 

- **TACRED**

  


### 1.4. 评测标准

- P:   准确率

- R：召回率

- F1:  2*P*R/(p+R)

  

## 2. 方法总结

### 2.1. 基于模板的方法

**模板匹配**：是关系分类中最常见的方法，使用一个模板库对输入文本两个给定实体进行上下文匹配，如果满足模板对应关系，则作为实体对之间的关系。常见的模板匹配方法主要包括：

- **人工模板**：主要用于判断实体间是否存在上下位关系。上下位关系的自然语言表达方式相对有限，采用人工模板就可以很好完成关系分类。但对于自然语言表达形式非常多的关系类型而言，这就需要采取统计模板。
- **统计模板**：无须人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。



#### 2.1.1. 基于触发词/字符串
例：句子中上下位关系，比如hyponym(China; Asia countries)。从下面两个句子中都可以抽取出这种关系：

Asia countries, especially China, Japan, and India...

Asia countries, such as China, Japan, and India...

两个实体之间的especially和such as可以看做这种关系的特征。寻找更多表达这种关系的句子，构造规则模板，即可用于抽取构成上下位关系的实体，从而发现新的三元组。

#### 2.1.2 基于依存句法的方法

使用NLP工具获取句子相关特征，对处理结果一般进行如下处理：

1. 对输入句子进行分词、词性标注、命名实体识别、依存分析等处理
2. 根据句子依存句法树结构进行规则匹配，每匹配一条规则就生成一个三元组
3. 根据扩展规则对抽取到的三元组进行扩展
4. 对三元组实体和触发词进一步处理抽取出关系

####  小结

手写规则的 **优点** ：

- 人工规则有高准确率(high-precision)
- 可以为特定领域定制(tailor)
- 在小规模数据集上容易实现，构建简单

**缺点**：

- 低召回率(low-recall)
- 特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力
- 需要为每条关系来定义 pattern
- 难以维护
- 可移植性差



### 2.2 监督学习

有监督的关系抽取方法：

- 基于特征工程的方法：需要显示地将关系实例转换成分类器可以接受的特征向量
- 基于核函数的方法：直接以结构树为处理对象，在计算关系之间距离的时候不再使用特征向量的内积而是用核函数
- 基于神经网络的方法：直接从输入的文本中自动学习有效的特征表示，是一个端到端的过程

#### 2.2.1. 机器学习
将关系抽取看成是一个基于构造特征的分类问题

**常见特征**：

- 实体特征，包括实体前后的词，实体类型，实体之间的距离等

- chunk，如 NP，VP，PP 这类短语

- 实体间的依存关系，实体间树结构的距离，及其他特定的结构信息

  

**标准流程**：

- 预先定义提取的关系集合
- 选择相关命名实体集合
- 寻找并标注数据
- 选择有代表性的语料库
- 标记命名实体
- 人工标注实体间关系
- 分割训练、开发、测试集
- 设计特征
- 选择并训练分类器
- 评估结果

通常会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用基于具体任务的特征集。常用的分类器包括 **MaxEnt、Naive Bayes、SVM** 等。



#### 2.2.2. 深度学习（Pipeline vs Joint Model）

**Pipeline**

Pipeline方法先在句子中抽取实体、而后再抽取关系。即把实体识别和关系分类作为两个完全独立的过程，互不影响，关系的识别依赖于实体识别的效果。

...

**Joint Model**

现有联合抽取模型总体上有两大类：

1、**共享参数**的联合抽取模型

通过共享参数（共享输入特征或者内部隐层状态）实现联合，此种方法对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间交互不强。

绝大数文献还是基于参数共享进行联合抽取的，这类的代表文献有：

2、**联合解码**的联合抽取模型

为了加强实体模型和关系模型的交互，复杂的联合解码算法被提出来，比如整数线性规划等。这种情况下**需要对子模型特征的丰富性以及联合解码的精确性之间做权衡**：

- 一方面如果设计精确的联合解码算法，往往需要对特征进行限制，例如用条件随机场建模，使用维特比解码算法可以得到全局最优解，但是往往需要限制特征的阶数。
- 另一方面如果使用近似解码算法，比如集束搜索，在特征方面可以抽取任意阶的特征，但是解码得到的结果是不精确的。

因此，需要一个算法可以在不影响子模型特征丰富性的条件下加强子模型之间的交互。

此外，很多方法再进行实体抽取时并没有直接用到关系的信息，然而这种信息是很重要的。需要一个方法可以**同时考虑一个句子中所有实体、实体与关系、关系与关系之间的交互**。



**Pipeline对比 Joint Model**：

相比于传统的Pipeline方法，联合抽取能获得更好的性能。虽然Pipeline方法易于实现，这两个抽取模型的灵活性高，实体模型和关系模型可以使用独立的数据集，并不需要同时标注实体和关系的数据集。但存在以下缺点：

1. 误差积累：实体抽取的错误会影响下一步关系抽取的性能。
2. 实体冗余：由于先对抽取的实体进行两两配对，然后再进行关系分类，没有关系的候选实体对所带来的冗余信息，会提升错误率、增加计算复杂度。
3. 交互缺失：忽略了这两个任务之间的内在联系和依赖关系。





### 2.3. 基于半监督/无监督方法

#### 2.3.1  Bootstrapping

**Bootstrapping**：利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中并不断迭代。Bootstrapping的优点构建成本低，适合大规模的关系任务并且具备发现新关系的能力，但也存在对初始种子较为敏感、存在语义漂移、准确率等问题。Bootstrapping 如今在工业界中依旧是快速构建大规模知识图谱的重要方法。在实际使用中，可以考虑结合基于深度语义模型的关系抽取方法，进一步提高图谱召回。

**工业应用**：

bootstrapping比较常见的方法有**DIPRE**和**Snowball**。和**DIPRE**相比，**Snowball**通过对获得的模板pattern进行置信度计算，一定程度上可以保证抽取结果质量。

**DIPRE: Dual Iterative Pattern Expansion**

DIPRE是从HTML文档集合中提取结构化关系（或表格）的一种方法。 该方法在类似Web的环境下效果最好，其中的表格要提取的tuples往往会在反复出现在集合文档中一致的context内。 DIPRE利用这种集合冗余和内在的结构以提取目标关系并简化训练。

**DIPRE Pipeline**

DIPRE pattern由5-tuple *<order, urlprefix, left, middle, right>*组成，并通过将具有相等字符串分隔实体（*middle*）的共现种子tuples group在一起生成，然后将 *left* 字符串和 *right* 字符串分别设置为实体左侧和右侧上下文的最长公共子字符串。 *order* 反映了实体出现的顺序，*urlprefix* 设置为发现了 tuples 的源URL的最长公共子串。在从最初的种子 tuples 中生成一些 pattern 之后，DIPRE扫描包含 pattern 可匹配的文本片段的可用文档。随后，DIPRE生成新的tuples，并将它们用作新的“种子”。DIPRE反复迭代以上过程找到文档中的新 tuples 以识别新的可靠 patterns。

伪代码：

```text
收集具有关系R的一组种子tuples

迭代： 
1.找到包含这些种子tuples的句子 
2.查看种子tuples之间或周围的上下文，并泛化该上下文以生成patterns
3.用这些patterns找到更多种子tuples
```

**DIPRE样例**

![img](https://picb.zhimg.com/80/v2-d956babcee55223cbeff961f04bdd698_720w.jpg)图4. DIPRE样例

从 5 个种子 tuples 开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 (author,book) 抽取到了 relation pattern，***x, by y***, 和 ***x, one of y’s***。

**DIPRE利弊**

**优点：**

1. 能够从非结构化文本中抽取出结构化的关系
2. 训练成本低，每个新场景只需要少量种子tuples。

**缺点：**

1. 依赖 HTML 标签
2. 缺少对新 pattern 和 tuples 的评估
3. 抽取结果噪声较多
4. 抽取结果 Recall 较低







#### 2.3.2  基于远程监督的方法

远程监督算法基于一个非常重要的假设：**对于一个已有的知识图谱中的一个三元组（由一对实体和一个关系构成），外部文档库中任何包含这对实体的句子，在一定程度上都反映了这种关系。**基于这个假设，远程监督算法可以基于一个标注好的小型知识图谱，给外部文档库中的句子标注关系标签，相当于做了样本的自动标注，因此是一种半监督的算法。

**（1）多示例学习**：主要基于Bag的特征进行关系分类，主要代表文献包括PCNN[1]、Selective Attention over Instances[2]、Multi-label CNNs[3]、APCNNs[4]，其中Bag的表示主要方式和池化方式为：

[![img](https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67)](https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67)

**（2）强化学习**：在采用多示例学习策略时，可能会出现整个Bag包含大量噪声的情况。基于强化学习的CNN+RL[5]比句子级别和Bag级别的关系分类模型取得更好效果。

模型主要由样例选择器和关系分类器构成。样例选择器负责从样例中选择高质量的句子，采取强化学习方式在考虑当前句子的选择状态下选择样例；关系分类器向样例选择器反馈，改进选择策略。

[![img](https://camo.githubusercontent.com/6f940358180f96ad8ecb82acfe5b60b70f664891/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d63343265376661656666613765386638396237623964353031393861303661615f31343430772e6a7067)](https://camo.githubusercontent.com/6f940358180f96ad8ecb82acfe5b60b70f664891/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d63343265376661656666613765386638396237623964353031393861303661615f31343430772e6a7067)CNN+RL

**（3）预训练机制**：采取“Matching the Blank[6]”方法，首次在预训练过程中引入关系分类目标，但仍然是自监督的，没有引入知识库和额外的人工标注，将实体metion替换为「BLANK」标识符。

- 该方法认为包含相同实体对的句子对为正样本，而实体对不一样的句子对为负样本。如图，rA和rB构成正样本，rA和rC构成rB和rC构负样本。
- 不同于传统的远程监督，该方法训练中不使用关系标签，采用二元分类器对句子对进行相似度计算。预训练的损失包含2部分：MLM loss 和 二元交叉熵关系损失。
- 在FewRel数据集上，不进行任何tuning就已经超过了有监督的结果。

[![img](https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67)](https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67)





## 3. 抽取工具应用

### 3.1 TextRunner

**TEXTRUNNER**三个关键步骤：

Open Information Extraction from the Web(TextRunner, 2007，华盛顿大学)

- **Self-Supervised Learner**：构造训练数据集，学习一个贝叶斯分类器，判断(e*i, relation words, e_*j)是否是可信的关系
- **Single-Pass Extractor**：输入一句话，产生所有可能的候选三元组，使用分类器判别，保留可信的三元组
- **Redundancy-Based Assessor**：统计(e_*i, relation words, e_*j)发生在不同句子中的频次，保留高频词的结果作为最终结果

**Self-Supervised Learner:**

- **parsing:** 在一个小的数据集进行**语法解析**，解析句子中的名词短语

- **构造三元组：**将名词短语作为可能的实体e_i，两个名词短语之间的词语作为关系，构成三元组候选集合

- **使用约束构造正负样本：** 满足下述三个条件的作为正样本

- - e*i e_j存在依赖路径，并且路径长度小于一定的值*
  - The path from ei to ej along the syntax tree does not cross a sentence-like boundary (e.g. relative clauses)
  - e*i e*j都不是代词

- **训练分类器：**三元组 ![[公式]](https://www.zhihu.com/equation?tex=%28e_i%2C+r_%7Bi%2Cj%7D%2C+e_j%29) ,将三元组特征化，训练一个贝叶斯分类器；特征有

- - presence of part-of-speech tag sequences in the relation ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - the number of tokens in ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - the number of stopwords in ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bi%2Cj%7D)
  - whether or not an object e is found to be a proper noun
  - the part-of-speech tag to the left of ei
  - the part-of-speech tag to the right of ej .

**Single-Pass Extractor:**

输入一个句子，处理过程如下

- **先进行词性标注**，然后使用lightweight noun phrase chunker识别名词短语
- 识别**名词短语之间的词语**作为关系表示
- 使用分类器进行分类，判别这个三元组候选是否可信

**Redundancy-based Assessor：**

- 会通过启发式的规则归一化关系短语，比如去除不必要的修饰词语
- 统计三元组的频数，如果这个三元组是从k个不同的句子中抽取得到的话



### 3.2 OLLIE：开放三元组知识抽取

OLLIE支持基于语法依赖树的关系抽取。流程图如下，主要包含三个步骤

- **Constructing a Bootstrapping Set：**使用REVERB已经抽取到的高质量的三元组作为Seed Tuples，使用Seed Tuple抽取包含这些seed tuple的句子，构造一个比较大的训练数据集
- **Open Pattern Learning：**基于语法解析，使用训练数据集学习open pattern templates/抽取模式模板
- **Pattern Matching for Extraction：**使用学习到的open pattern templates来抽取新的三元组

![img](https://pic1.zhimg.com/80/v2-8311729f9eacd65654c353b25872ccb3_720w.jpg)







## 4. 相关链接

1. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks. EMNLP
2. Attention over Instances (Lin 2016)
3. Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks.
4. Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions
5. Reinforcement Learning for Relation Classification from Noisy Data
6. [Matching the Blanks: Distributional Similarity for Relation Learning]( https://arxiv.org/pdf/1906.03158.pdf)

## 5. 参考资源
[https://zhuanlan.zhihu.com/p/139485679](https://zhuanlan.zhihu.com/p/139485679)